---
author: "Vo Chi Cong"
title: "Tìm lỗi quan sát nhãn dữ liệu"
date: 8th July 2022

---

$$
\newcommand{\vect}[1]{{\boldsymbol{{#1}}}}
\newcommand{\x}{\vect{x}}
\newcommand{\X}{\vect{X}}
\newcommand{\model}{\vect{\theta}}
\newcommand{\C}{\hat{\vect{C}}}
\newcommand{\Ccheck}{\check{\vect{C}}}
\newcommand{\ystar}{y^{*}}
\newcommand{\ytilde}{\tilde{y}}
\newcommand{\argmax}{\mathop{\rm arg~max}\limits}
\newcommand{\defined}{≔}
$$

## Mở bài

Có một bộ dữ liệu bảng số, được gắn nhãn để phân loại, ví dụ nhãn dương tính và âm tính. Giả sử các nhãn dương tính có độ tin cậy cao, còn các nhãn âm tính có độ tin cậy thấp hơn, có thể xem như chứa cả dữ liệu dương tính chưa bộc phát. Lấy ví dụ với dữ liệu đánh giá tín dụng thì những ca vỡ nợ sẽ có nhãn dương tính. Với dữ liệu khám nghiệm ung thư thì những ca đã phát bệnh là dương tính.

_Giả sử phân bố nhãn trong bộ dữ liệu trên có tương quan đủ mạnh với phân bố nhãn tiềm ẩn thật sự_. Trong phân bố nhãn có tiềm ẩn tính đa dạng, bất định mang tính bản chất. Ví dụ có 10 người có các thuộc tính xấu gần giống nhau, nhưng sẽ trong đó sẽ chỉ có 8 người ngẫu nhiên nào đó vỡ nợ, hoặc bị ung thư.

Bộ dữ liệu trên có một số lượng nhất định các nhãn bị gắn sai. Có thể nào xác định được ranh giới để phân biệt được lỗi gắn nhãn với tính bất định bản chất của dữ liệu hay không?

_Giả sử rằng suất nhãn bị gán sai không phụ thuộc vào từng ca dữ liệu cụ thể mà chỉ phụ thuộc vào đặc tính của các lớp nhãn dữ liệu_. Ví dụ trường hợp phân loại 3 loài vật là chó, mèo và chuột, thì xác suất nhầm chó với mèo cao hơn là nhầm mèo với chuột hoặc chó với chuột.

Có một mô hình dự đoán xác suất dương tính đối với bộ dữ liệu nêu trên. _Giả sử xác suất do mô hình đưa ra có tương quan đủ mạnh đối với phân bố thật sự của nhãn_.

Với những giả sử nêu trên, ta có thể ước lượng được xác suất nhãn gắn trên một ca dữ liệu là thật sự đúng hay không

## Lỗi quan sát nhãn là gì?

Với một đối tượng khảo sát, quan sát viên sẽ quan sát, xem xét, nghiên cứu rồi gán một nhãn nhất định cho dữ liệu đó. Trong môi trường lý tưởng thì ta sẽ nhận định và gán đúng nhãn “chân lý" cho đối tượng.

![restroom_icon_url](https://cdn-icons-png.flaticon.com/128/995/995035.png)

[Restroom icons created by Freepik — Flaticon](https://www.flaticon.com/free-icons/restroom)

Ví dụ ta có thể quan sát ngực, bụng, mông của một người nào đó và nhận định giới tính. Trong thực tế thì có thể xảy ra nhầm lẫn ở một bước nào đó trong quá trình từ khi bắt đầu quan sát cho đến khi gắn xong nhãn. Nhầm lẫn đó có thể dẫn tới gán nhầm nhãn “Nam” cho đối tượng vốn là “Nữ”, hoặc ngược lại. Chúng ta gọi "lỗi quan sát nhãn" và "lỗi gắn nhãn" với cùng một ý nghĩa.

Có thể có một số nam giới và nữ giới có số đo 3 vòng khá giống nhau, nhưng “đương nhiên" họ có 2 giới tính khác nhau, tức là các nhãn “chân lý" của họ là khác nhau về bản chất, chứ không nhất thiết có liên quan đến việc gắn nhãn có lỗi hay không.

Nói cách khác từ số đo 3 vòng ta có thể không suy đoán được chắc chắn 100% nhưng có thể tính được xác suất giới tính Nam/Nữ của đối tượng. Quy tắc hay mô hình suy đoán có thể học được từ một tập dữ liệu có số đo 3 vòng và giới tính tương ứng của nhiều mẫu người khác nhau. Nếu trong tập dữ liệu này có những nhãn giới tính bị gắn sai thì việc học xác suất “chân lý” sẽ bị lệch lạc.

## Định nghĩa và ký hiệu


### Quy trình nhiễu theo lớp

Giả sử có một bộ dữ liệu số được gắn nhãn phân loại thành $m$ lớp khác nhau
$[m] \defined {1,2,\ldots,m}$.
Giả sử đối với mỗi mẫu dữ liệu ta có một nhãn "tiềm ẩn" thật là $\ystar$.
Trước khi quan sát được nhãn $\ytilde$, giả sử có một quy trình gây nhiễu
biến $\ystar=j$ thành $\ytilde=i$ với xác suất
$p(\ytilde=i, \ystar=j)$ chỉ phụ thuộc vào $i,j \in [m]$ và độc lập với các mẫu dữ liệu cụ thể,

$p(\ytilde| \ystar; \vect{x}) = p(\ytilde| \ystar) \forall\vect{x}.$

Ví dụ khi phân loại 3 loài vật là chó, mèo và chuột, thì xác suất nhầm chó với mèo cao hơn là nhầm mèo với chuột hoặc chó với chuột, và xác suất đó không phụ thuộc vào từng con cho, con mèo hoặc con chuột cụ thể. Giả sử này là hợp lý và thường được sử dụng trong các nghiên cứu về xử lý nhiễu (Goldberger and Ben-Reuven, 2017; Sukhbaatar et al., 2015).

### Ma trận nhiễu theo lớp
$\boldsymbol{Q}_{\ytilde, \ystar} \defined \left[ {\begin{array}{ccc}
    p(\ytilde=1, \ystar=1) & \ldots & p(\ytilde=1, \ystar=m) \\
    \vdots & p(\ytilde=i, \ystar=j) & \vdots \\
    p(\ytilde=m, \ystar=1) & \ldots & p(\ytilde=m, \ystar=m) \\
  \end{array} } \right]$
là ma trận kích thước $m\times m$ thể hiện phân phối xác suất đồng thời cho $\ytilde$ và $\ystar.$

**Độ thưa** là tỷ lệ số $0$ chiếm lĩnh các vị trí ngoại trừ đường chéo của ma trận $\vect{Q}_{\ytilde,\ystar}$: độ thưa bằng $0$ nói rằng mọi tỷ lệ nhiễu $p_{\ytilde,\ystar}$ đều khác $0$, còn độ thưa $1$ thể hiện tình trạng lý tưởng, hoàn toàn không có nhiễu trong nhãn.

Gọi $\X_{\ytilde=i}$ là tập hợp các mẫu $\x$ đã được gán nhãn $\ytilde=i$.
**Độ tự tin** $\hat{p}(\ytilde=i; \vect{x}\in\vect{X}_{\ytilde=i},\model)$
là xác suất mô hình $\model$ đưa ra đối với mẫu $\vect{x}$, dự đoán nó có label đúng như label $\ytilde$ đã được gán. *Độ tự tin thấp là một dấu hiệu của khả năng nhãn có lỗi.*

## Phương pháp học tự tin

Confident Learning Method

**Đầu vào**

1. Các nhãn $\ytilde_k$ đã quan sát được đối với các mẫu $\x_k\in\X$
2. Xác suất $\hat{p}(\ytilde=i; \vect{x}_k\in\vect{X})$ dự đoán mẫu $\x_k\in\X$ có nhãn $i\in[m]$

**Các bước**

1. Tính $t_i$, độ tự tin trung bình  trong từng lớp $i\in[m]$
2. Ước lượng phân bố xác suất đồng thời $\boldsymbol{\hat{Q}}_{\ytilde, \ystar}$ cho nhãn quan sát và nhãn thật
3. *Lọc và xếp hạng các mẫu theo mức độ khả nghi nhãn bị lỗi*
4. Loại bỏ các mẫu khả nghi nhất là nhãn bị lỗi
5. Đặt trọng số cho các mẫu trong từng lớp $i\in[m]$ để học lại mô hình $\model$

### Chỉ tiêu tự tin

Với mỗi lớp $i\in[m]$ ta có thể chọn một chỉ tiêu tự tin $t_j\in(0,1)$.
Chỉ tiêu này sẽ được dùng để thiết lập ma trận tự tin $(\ref{eq1})$.
Một cách chọn chỉ tiêu tự tin là dùng độ tự tin trung bình $(\ref{eq2})$.
Đối với từng mẫu $\x$ và từng nhãn $i$, giá trị xác suất dự đoán
$\hat{p}(\ytilde=i; \vect{x},\model)$ đưa ra bởi mô hình $\model$,
nếu không nhỏ chỉ tiêu $t_i$ thì ta cho rằng có khả năng nhãn $i$ đúng cho mẫu $\x$.
Tập hợp các nhãn $i$'s có thể đúng với mẫu $\x$ là

$\left\{l\in[m]: \hat{p}(\ytilde=l;\x,\model)\geq t_l\right\}\neq\emptyset;$

Trong tập đó thì nhãn $j$ có xác suất dự đoán lớn nhất có vẻ là lớp "thật" của $\x$.

### Ma trận đếm cặp nhãn

Gọi $\X_{\ytilde=i,\ystar=j}$ là tập (không tường minh) các mẫu có nhãn quan sát là $i$ và nhãn thật là $j$, ta ước lượng nó như sau bằng cách sử dụng các chỉ tiêu tự tin $t_j$ cho từng lớp $j\in[m]$:

$\hat{\X}_{\ytilde=i,\ystar=j} \defined
\left\{\x\in\X_{\ytilde=i}:
\mathop{\rm arg max}
\limits_{l\in[m]: \hat{p}(\ytilde=l;\x,\model)\geq t_l}
\hat{p}(\ytilde=l;\x,\model) \equiv j
\right\}\label{eq1}\tag{1}$

Ma trận đếm cặp nhãn $\C_{\ytilde,\ystar}$ kích thước $m\times m$
lưu số phần tử của các tập $\hat{\X}_{\ytilde=i,\ystar=j}$,

$\C_{\ytilde=i,\ystar=j} \defined  |\hat{\X}_{\ytilde=i,\ystar=j} |.$

Số lượng mẫu được quan sát có nhãn $\ytilde=i$ là
$\vect{C}_{\ytilde=i} \defined |\X_{\ytilde=i}|.$
Vì $(\ref{eq1})$ chỉ là ước lượng của $\X_{\ytilde=i,\ystar=j}$ cho nên
nếu đặt $\C_{\ytilde=i} \defined \sum_{j\in[m]}\C_{\ytilde=i,\ystar=j}$
thì có thể
$\C_{\ytilde=i} \neq \vect{C}_{\ytilde=i}.$

Ví dụ $\C_{\ytilde=3,\ystar=1} = 10$ có nghĩa là, ta đếm được
10 mẫu được gán nhãn $3$ nhưng "thật ra" nên có nhãn $1$.

### Độ tự tin trung bình

Độ tự tin trung bình trong lớp $i\in[m]$ là

$t_i = \frac{1}{\C_{\ytilde=i}} \sum_{\x\in\X_{\ytilde=i}}
\hat{p}(\ytilde=i; \vect{x},\model)
\label{eq2}\tag{2}$


### Ước lượng ma trận nhiễu

Hiệu chỉnh ma trận đếm cặp nhãn qua hai bước
1. Hiệu chỉnh từng dòng theo số mẫu của từng lớp đã quan sát $i\in[m]$
$\check{Q}_{\ytilde=i,\ystar=j} = \C_{\ytilde=i,\ystar=j}\frac{\vect{C}_{\ytilde=i}}{\C_{\ytilde=i}}\label{eq3a}\tag{3a}$
2. Chia đều toàn bộ để tổng số các yếu tố trở thành $1$
$\hat{Q}_{\ytilde=i,\ystar=j}=\frac{\check{Q}_{\ytilde=i,\ystar=j}}{\sum_{i\in[m],j\in[m]}\check{Q}_{\ytilde=i,\ystar=j}}\label{eq3b}\tag{3b}$

### Lọc và xếp hạng nhãn lỗi

Với phương pháp đơn giản nhất,
các mẫu $\left\{\x\in\hat{\X}_{\ytilde=i,\ystar=j}: i\neq j\right\}$
nằm ngoài đường chéo của ma trận
$\hat{\X}_{\ytilde,\ystar}$
bị tình nghi là có nhãn lỗi.
Các mẫu đó được xếp hạng mức độ khả nghi
theo dựa theo xác suất do mô hình $\model$ dự đoán

$\hat{e}({\x\in\X_{\ytilde=i}, \model}) \defined \max_{j\neq i}{\hat{p}(\ytilde=j; \x,\model)}
-\hat{p}(\ytilde=i; \x,\model)$

theo cách làm trong CleanLab của Curtis et al.’s (2021), và đảo dấu so với Wei et al.’s (2018).

Curtis et al.’s (2021) trình bày một số
phương pháp khác dùng ma trận nhiễu $(\ref{eq3b})$
để chọn lọc và xếp hạng nhãn khả nghi có lỗi.

## Tương lai

Một số hướng nghiên cứu tương lai

- Tối ưu hóa giá trị chỉ tiêu tự tin
- Xử lý với bài toán hồi quy
- Tương tác qua lại giữa việc học mô hình và việc khử lỗi

## **Tham khảo**

- Curtis G. Northcutt and Lu Jiang and Isaac L. Chuang (2021). Confident Learning: Estimating Uncertainty in Dataset Labels. Journal of Artificial Intelligence Research (JAIR)
- [An Introduction to Confident Learning: Finding and Learning with Label Errors in Datasets (curtisnorthcutt.com)](https://l7.curtisnorthcutt.com/confident-learning)
- [cleanlab/cleanlab: The standard data-centric AI package for data quality and machine learning with messy, real-world data and labels. (github.com)](https://github.com/cleanlab/cleanlab)
- [Are Label Errors Imperative? Is Confident Learning Useful? | by Suneeta Mall | May, 2022 | Towards Data Science (medium.com)](https://medium.com/towards-data-science/confident-learning-err-did-you-say-your-data-is-clean-ef2597903328)
- Wei, C., Lee, J. D., Liu, Q., and Ma, T. (2018). On the margin theory of feedforward neural networks. Computing Research Repository (CoRR)
